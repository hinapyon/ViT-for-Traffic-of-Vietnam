{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FIL5JwkLvmgF"
      },
      "outputs": [],
      "source": [
        "#ライブラリをインポート\n",
        "import os #OSに依存する様々な機能を利用するためのモジュール(ファイルやディレクトリ操作など)\n",
        "import re #正規表現を利用するためのモジュール\n",
        "import csv  #csvファイルを扱うためのモジュール\n",
        "import math #数学的計算のためのモジュール\n",
        "import cv2 #画像処理のためのモジュール\n",
        "import matplotlib.pyplot as plt #グラフ描画のためのモジュール\n",
        "import numpy as np  #多次元配列計算のためのモジュール\n",
        "import pandas as pd #データフレームを扱うためのモジュール\n",
        "from scipy import signal  #信号処理のためのモジュール\n",
        "from scipy.stats import skew, kurtosis  #歪度と尖度を調べるためのモジュール\n",
        "from sklearn.model_selection import train_test_split  #データをトレーニング用とテスト用に分けるためのモジュール\n",
        "from sklearn import preprocessing #データを正規化するためのモジュール\n",
        "from sklearn.preprocessing import StandardScaler  #データを標準化するためのモジュール\n",
        "from sklearn.preprocessing import LabelEncoder  #カテゴリ変数を数値化するためのモジュール\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score #機械学習モデルの性能評価のためのモジュール\n",
        "import tensorflow as tf #TensorFlow(Googleが開発したオープンソースの機械学習フレームワーク)\n",
        "from tensorflow import keras  #TensorFlow用のニューラルネットワークライブラリAPI\n",
        "from tensorflow.keras import layers #ニューラルネットワークのレイヤーを定義するためのモジュール\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#メモ\n",
        "#画像のサイズは縦：横=1088:1920=17:30"
      ],
      "metadata": {
        "id": "uBng5g_POIMN"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#自分のGoogle Driveとドッキング\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mA1YMpwR6sKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77618ede-4875-47a6-90c3-4e41b0132121"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPUを使うための処理\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "mLiR9zG46pL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86e92ea-ceb0-453d-c31e-ab8f5115055a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#正解データへのパスとファイル名取得\n",
        "CollectPath = \"/content/drive/MyDrive/DICOMO/正解データ/\"\n",
        "CollectFilename = os.listdir(CollectPath)"
      ],
      "metadata": {
        "id": "x6tK7UwN6wjE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#不正解データへのパスとファイル名取得\n",
        "IncollectPath = \"/content/drive/MyDrive/DICOMO/不正解データ/\"\n",
        "IncollectFilename = os.listdir(IncollectPath)"
      ],
      "metadata": {
        "id": "1d7zUuH065Sd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#教師データを格納するリストを定義\n",
        "img = []"
      ],
      "metadata": {
        "id": "xf2vfG5A-9Sn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#正解データをグレースケールに変換・縦170横300にリサイズ\n",
        "for i in CollectFilename:\n",
        "     image = cv2.imread(CollectPath+i)\n",
        "     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "     image = cv2.resize(image, dsize=(300, 170))\n",
        "     img.append(image)"
      ],
      "metadata": {
        "id": "9Da_Q-hE7W1h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#不正解データをグレースケールに変換・縦170横300にリサイズ\n",
        "for i in IncollectFilename:\n",
        "     image = cv2.imread(IncollectPath+i)\n",
        "     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "     image = cv2.resize(image, dsize=(300, 170))\n",
        "     img.append(image)"
      ],
      "metadata": {
        "id": "Y_7SmlmiEdxb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#教師ラベルを作成\n",
        "#渡れる時を1、渡れない時を0とする\n",
        "CollectLabel = np.ones(len(CollectFilename))\n",
        "IncollectLabel = np.zeros(len(IncollectFilename))\n",
        "label = np.concatenate((CollectLabel, IncollectLabel))"
      ],
      "metadata": {
        "id": "3P6f3AUkK37r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LTzgPvYpvmgI"
      },
      "outputs": [],
      "source": [
        "#マクロの定義\n",
        "N = 1 #Encoderの層の数\n",
        "NUM_HEADS =  16\n",
        "KEY_DIM = 600\n",
        "DROPOUT = 0.1 #ドロップアウト率"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.array(img)\n",
        "img = np_utils.to_categorical(img)"
      ],
      "metadata": {
        "id": "Gu6PfaPBVpnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#トレーニングデータとテストデータの分割\n",
        "x_train, x_test, y_train, y_test = train_test_split(img, label, train_size = 0.8, shuffle = True)"
      ],
      "metadata": {
        "id": "etta0ZrRNH89"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wtuGZkGEvmgJ"
      },
      "outputs": [],
      "source": [
        "# Define the input shape\n",
        "input_shape = (170, 300)\n",
        "output_shape = (1,)\n",
        "\n",
        "#形を定義(このモジュールは行列でないとダメっぽい)\n",
        "inputs_encoder = layers.Input(shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IetrZZbZvmgJ"
      },
      "outputs": [],
      "source": [
        "#Encoderに対する入力の形状\n",
        "x_encoder = layers.Reshape((85, 600))(inputs_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "a5rxcbGMvmgK"
      },
      "outputs": [],
      "source": [
        "#Transformer Encoder Layer(BERT)\n",
        "for i in range(N):\n",
        "      #Multi-Head-Attention Layer\n",
        "      attention_encoder = layers.MultiHeadAttention(num_heads=NUM_HEADS, key_dim=KEY_DIM, use_bias=True)(x_encoder, x_encoder, x_encoder)\n",
        "\n",
        "      #Dropout Layer\n",
        "      attention_encoder = layers.Dropout(rate=DROPOUT)(attention_encoder)\n",
        "      #Add & Norm Layer\n",
        "      attention_encoder = layers.LayerNormalization()(x_encoder + attention_encoder)\n",
        "\n",
        "      #Feed-Forward-Network\n",
        "      ffn_encoder = layers.Dense(600 * 4, use_bias=True, activation=\"relu\")(attention_encoder)\n",
        "      ffn_encoder = layers.Dense(600, use_bias=True)(ffn_encoder)\n",
        "\n",
        "      #Dropout Layer\n",
        "      ffn_encoder = layers.Dropout(rate=DROPOUT)(ffn_encoder)\n",
        "      #Add & Norm Layer\n",
        "      x_encoder = layers.LayerNormalization()(attention_encoder + ffn_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pHb0FNugvmgK"
      },
      "outputs": [],
      "source": [
        "x = layers.Flatten()(x_encoder)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d1g0p_6xvmgL"
      },
      "outputs": [],
      "source": [
        "model = keras.Model(inputs=inputs_encoder, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G_l6F_cPvmgL"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].shape"
      ],
      "metadata": {
        "id": "_xYqfutEUhVp",
        "outputId": "591b69aa-2af3-4bfb-db06-922527936dc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(170, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=32, epochs=300, shuffle=True, validation_split=0.2)\n",
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaG-w85ZSawR",
        "outputId": "9abd4611-7500-471b-82ce-a09e2eba81e2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "13/13 [==============================] - 12s 170ms/step - loss: 15.1760 - accuracy: 0.4651 - val_loss: 1.7424 - val_accuracy: 0.4536\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 2s 140ms/step - loss: 2.8530 - accuracy: 0.5220 - val_loss: 0.8965 - val_accuracy: 0.4536\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 1.4820 - accuracy: 0.4625 - val_loss: 0.6891 - val_accuracy: 0.5464\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 2s 141ms/step - loss: 1.1597 - accuracy: 0.4470 - val_loss: 0.9643 - val_accuracy: 0.4536\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 2s 140ms/step - loss: 1.0160 - accuracy: 0.4574 - val_loss: 0.6910 - val_accuracy: 0.5464\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 2s 128ms/step - loss: 1.3517 - accuracy: 0.4884 - val_loss: 0.8184 - val_accuracy: 0.4536\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 2s 139ms/step - loss: 1.0730 - accuracy: 0.4858 - val_loss: 0.7113 - val_accuracy: 0.5464\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 2s 128ms/step - loss: 0.8867 - accuracy: 0.4884 - val_loss: 0.6914 - val_accuracy: 0.5464\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 2s 128ms/step - loss: 0.8035 - accuracy: 0.4574 - val_loss: 0.6890 - val_accuracy: 0.5464\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.7644 - accuracy: 0.4935 - val_loss: 0.6906 - val_accuracy: 0.5464\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.7455 - accuracy: 0.5039 - val_loss: 0.6898 - val_accuracy: 0.5464\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.7647 - accuracy: 0.4470 - val_loss: 0.6915 - val_accuracy: 0.5464\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 2s 141ms/step - loss: 0.7830 - accuracy: 0.4729 - val_loss: 0.6894 - val_accuracy: 0.5464\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.7268 - accuracy: 0.4987 - val_loss: 0.6889 - val_accuracy: 0.5464\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.7172 - accuracy: 0.4832 - val_loss: 0.6893 - val_accuracy: 0.5464\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.7054 - accuracy: 0.4806 - val_loss: 0.6948 - val_accuracy: 0.4536\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.6837 - accuracy: 0.5401 - val_loss: 0.6947 - val_accuracy: 0.4536\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6941 - accuracy: 0.4832 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.7082 - accuracy: 0.4729 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.7068 - accuracy: 0.4755 - val_loss: 0.6912 - val_accuracy: 0.5464\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 2s 142ms/step - loss: 0.7085 - accuracy: 0.4496 - val_loss: 0.6912 - val_accuracy: 0.5464\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 2s 142ms/step - loss: 0.7006 - accuracy: 0.4935 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 2s 142ms/step - loss: 0.7066 - accuracy: 0.4961 - val_loss: 0.6932 - val_accuracy: 0.4536\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.6992 - accuracy: 0.5297 - val_loss: 0.6969 - val_accuracy: 0.4536\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6971 - accuracy: 0.5013 - val_loss: 0.6946 - val_accuracy: 0.4536\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6906 - accuracy: 0.4806 - val_loss: 0.6912 - val_accuracy: 0.5464\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6956 - accuracy: 0.5220 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6990 - accuracy: 0.4910 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.7004 - accuracy: 0.5220 - val_loss: 0.6912 - val_accuracy: 0.5464\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6961 - accuracy: 0.5116 - val_loss: 0.6889 - val_accuracy: 0.5464\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6900 - accuracy: 0.5065 - val_loss: 0.6896 - val_accuracy: 0.5464\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.7002 - accuracy: 0.4780 - val_loss: 0.6896 - val_accuracy: 0.5464\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.7049 - accuracy: 0.4858 - val_loss: 0.6897 - val_accuracy: 0.5464\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6991 - accuracy: 0.5013 - val_loss: 0.6899 - val_accuracy: 0.5464\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6982 - accuracy: 0.4910 - val_loss: 0.6922 - val_accuracy: 0.5464\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6953 - accuracy: 0.4910 - val_loss: 0.6922 - val_accuracy: 0.5464\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6903 - accuracy: 0.5013 - val_loss: 0.6921 - val_accuracy: 0.5464\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6986 - accuracy: 0.4806 - val_loss: 0.6928 - val_accuracy: 0.5464\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6997 - accuracy: 0.4548 - val_loss: 0.6925 - val_accuracy: 0.5464\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.7146 - accuracy: 0.4987 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.7012 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5464\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.6999 - accuracy: 0.4574 - val_loss: 0.6930 - val_accuracy: 0.5464\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6914 - accuracy: 0.5142 - val_loss: 0.6924 - val_accuracy: 0.5464\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6980 - accuracy: 0.4961 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6974 - accuracy: 0.4884 - val_loss: 0.6930 - val_accuracy: 0.5464\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6931 - accuracy: 0.5556 - val_loss: 0.6925 - val_accuracy: 0.5464\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6984 - accuracy: 0.4574 - val_loss: 0.6917 - val_accuracy: 0.5464\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6995 - accuracy: 0.5090 - val_loss: 0.6921 - val_accuracy: 0.5464\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.6959 - accuracy: 0.5013 - val_loss: 0.6918 - val_accuracy: 0.5464\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.6958 - accuracy: 0.4935 - val_loss: 0.6917 - val_accuracy: 0.5464\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6957 - accuracy: 0.5168 - val_loss: 0.6952 - val_accuracy: 0.4536\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.7007 - accuracy: 0.5013 - val_loss: 0.6988 - val_accuracy: 0.4536\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6910 - accuracy: 0.5090 - val_loss: 0.6962 - val_accuracy: 0.4536\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6944 - accuracy: 0.4961 - val_loss: 0.6928 - val_accuracy: 0.5464\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6956 - accuracy: 0.4729 - val_loss: 0.6918 - val_accuracy: 0.5464\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 2s 140ms/step - loss: 0.7039 - accuracy: 0.4729 - val_loss: 0.6922 - val_accuracy: 0.5464\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.6927 - accuracy: 0.4910 - val_loss: 0.6922 - val_accuracy: 0.5464\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.6928 - accuracy: 0.5194 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.7057 - accuracy: 0.5271 - val_loss: 0.6945 - val_accuracy: 0.4536\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.7030 - accuracy: 0.5297 - val_loss: 0.6951 - val_accuracy: 0.4536\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.7005 - accuracy: 0.5090 - val_loss: 0.6947 - val_accuracy: 0.4536\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.7015 - accuracy: 0.4341 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 2s 150ms/step - loss: 0.7044 - accuracy: 0.5090 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6917 - accuracy: 0.5039 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.7014 - accuracy: 0.4987 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.6956 - accuracy: 0.4651 - val_loss: 0.6931 - val_accuracy: 0.5464\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.6968 - accuracy: 0.5039 - val_loss: 0.6930 - val_accuracy: 0.5464\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.6921 - accuracy: 0.4729 - val_loss: 0.6931 - val_accuracy: 0.5464\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 2s 137ms/step - loss: 0.6905 - accuracy: 0.5168 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 2s 150ms/step - loss: 0.7003 - accuracy: 0.5297 - val_loss: 0.6927 - val_accuracy: 0.5464\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 2s 151ms/step - loss: 0.6935 - accuracy: 0.5297 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.6944 - accuracy: 0.4832 - val_loss: 0.6943 - val_accuracy: 0.4536\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 2s 137ms/step - loss: 0.6964 - accuracy: 0.4832 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 2s 137ms/step - loss: 0.6984 - accuracy: 0.5065 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.6943 - accuracy: 0.4961 - val_loss: 0.6932 - val_accuracy: 0.4536\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.6896 - accuracy: 0.4884 - val_loss: 0.6932 - val_accuracy: 0.4536\n",
            "Epoch 77/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6957 - accuracy: 0.4935 - val_loss: 0.6927 - val_accuracy: 0.5464\n",
            "Epoch 78/300\n",
            "13/13 [==============================] - 2s 151ms/step - loss: 0.6924 - accuracy: 0.5375 - val_loss: 0.6928 - val_accuracy: 0.5464\n",
            "Epoch 79/300\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.6984 - accuracy: 0.4470 - val_loss: 0.6927 - val_accuracy: 0.5464\n",
            "Epoch 80/300\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.6947 - accuracy: 0.5039 - val_loss: 0.6926 - val_accuracy: 0.5464\n",
            "Epoch 81/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6937 - accuracy: 0.5297 - val_loss: 0.6926 - val_accuracy: 0.5464\n",
            "Epoch 82/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6955 - accuracy: 0.4755 - val_loss: 0.6926 - val_accuracy: 0.5464\n",
            "Epoch 83/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.7049 - accuracy: 0.4574 - val_loss: 0.6926 - val_accuracy: 0.5464\n",
            "Epoch 84/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6925 - accuracy: 0.4910 - val_loss: 0.6927 - val_accuracy: 0.5464\n",
            "Epoch 85/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6933 - accuracy: 0.4910 - val_loss: 0.6927 - val_accuracy: 0.5464\n",
            "Epoch 86/300\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.6916 - accuracy: 0.4806 - val_loss: 0.6927 - val_accuracy: 0.5464\n",
            "Epoch 87/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.7008 - accuracy: 0.4677 - val_loss: 0.6928 - val_accuracy: 0.5464\n",
            "Epoch 88/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6948 - accuracy: 0.4729 - val_loss: 0.6927 - val_accuracy: 0.5464\n",
            "Epoch 89/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6963 - accuracy: 0.4884 - val_loss: 0.6927 - val_accuracy: 0.5464\n",
            "Epoch 90/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6926 - accuracy: 0.5168 - val_loss: 0.6927 - val_accuracy: 0.5464\n",
            "Epoch 91/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6903 - accuracy: 0.5013 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 92/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6992 - accuracy: 0.4832 - val_loss: 0.6930 - val_accuracy: 0.5464\n",
            "Epoch 93/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6929 - accuracy: 0.4806 - val_loss: 0.6932 - val_accuracy: 0.4536\n",
            "Epoch 94/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6911 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4536\n",
            "Epoch 95/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6970 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 96/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6916 - accuracy: 0.5013 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 97/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6920 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 98/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6918 - accuracy: 0.5039 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 99/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.7002 - accuracy: 0.5065 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 100/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6996 - accuracy: 0.5039 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 101/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6948 - accuracy: 0.5039 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 102/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6929 - accuracy: 0.4987 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 103/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6965 - accuracy: 0.5013 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 104/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6929 - accuracy: 0.5090 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 105/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6941 - accuracy: 0.5039 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 106/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6936 - accuracy: 0.5013 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 107/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6941 - accuracy: 0.5013 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 108/300\n",
            "13/13 [==============================] - 2s 139ms/step - loss: 0.6875 - accuracy: 0.5013 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 109/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.7014 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 110/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6952 - accuracy: 0.5065 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 111/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6937 - accuracy: 0.5013 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 112/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6925 - accuracy: 0.5090 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 113/300\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.6949 - accuracy: 0.4961 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 114/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6926 - accuracy: 0.5013 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 115/300\n",
            "13/13 [==============================] - 2s 150ms/step - loss: 0.7006 - accuracy: 0.5013 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 116/300\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.6933 - accuracy: 0.4987 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 117/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6944 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 118/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6943 - accuracy: 0.4780 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 119/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6934 - accuracy: 0.4935 - val_loss: 0.6932 - val_accuracy: 0.4536\n",
            "Epoch 120/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6933 - accuracy: 0.4832 - val_loss: 0.6932 - val_accuracy: 0.4536\n",
            "Epoch 121/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6914 - accuracy: 0.5142 - val_loss: 0.6932 - val_accuracy: 0.4536\n",
            "Epoch 122/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6933 - accuracy: 0.4858 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 123/300\n",
            "13/13 [==============================] - 2s 137ms/step - loss: 0.6930 - accuracy: 0.5349 - val_loss: 0.6932 - val_accuracy: 0.4536\n",
            "Epoch 124/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6931 - accuracy: 0.4677 - val_loss: 0.6932 - val_accuracy: 0.4536\n",
            "Epoch 125/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6915 - accuracy: 0.4755 - val_loss: 0.6931 - val_accuracy: 0.5464\n",
            "Epoch 126/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6986 - accuracy: 0.4910 - val_loss: 0.6930 - val_accuracy: 0.5464\n",
            "Epoch 127/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6952 - accuracy: 0.4832 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 128/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6938 - accuracy: 0.4961 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 129/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.7000 - accuracy: 0.4935 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 130/300\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.6918 - accuracy: 0.4935 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 131/300\n",
            "13/13 [==============================] - 2s 137ms/step - loss: 0.6943 - accuracy: 0.4935 - val_loss: 0.6912 - val_accuracy: 0.5464\n",
            "Epoch 132/300\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.6925 - accuracy: 0.4961 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 133/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6933 - accuracy: 0.5039 - val_loss: 0.6930 - val_accuracy: 0.5464\n",
            "Epoch 134/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6941 - accuracy: 0.5013 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 135/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6922 - accuracy: 0.4935 - val_loss: 0.6929 - val_accuracy: 0.5464\n",
            "Epoch 136/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6934 - accuracy: 0.4987 - val_loss: 0.6930 - val_accuracy: 0.5464\n",
            "Epoch 137/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.6953 - accuracy: 0.4935 - val_loss: 0.6930 - val_accuracy: 0.5464\n",
            "Epoch 138/300\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.6943 - accuracy: 0.4858 - val_loss: 0.6930 - val_accuracy: 0.5464\n",
            "Epoch 139/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6927 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5464\n",
            "Epoch 140/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6928 - accuracy: 0.5194 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 141/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6978 - accuracy: 0.4935 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 142/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6921 - accuracy: 0.5065 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 143/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6976 - accuracy: 0.5065 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 144/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.6983 - accuracy: 0.5142 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 145/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6891 - accuracy: 0.5194 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 146/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6938 - accuracy: 0.4910 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 147/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.7028 - accuracy: 0.4780 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 148/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 149/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6942 - accuracy: 0.5090 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 150/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6929 - accuracy: 0.5245 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 151/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6924 - accuracy: 0.5142 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 152/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6933 - accuracy: 0.4884 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 153/300\n",
            "13/13 [==============================] - 2s 137ms/step - loss: 0.6941 - accuracy: 0.4987 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 154/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6936 - accuracy: 0.4884 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 155/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6907 - accuracy: 0.5090 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 156/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6959 - accuracy: 0.4987 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 157/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6942 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 158/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6943 - val_accuracy: 0.4536\n",
            "Epoch 159/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6924 - accuracy: 0.5039 - val_loss: 0.6943 - val_accuracy: 0.4536\n",
            "Epoch 160/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.6932 - accuracy: 0.5116 - val_loss: 0.6945 - val_accuracy: 0.4536\n",
            "Epoch 161/300\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.6939 - accuracy: 0.5013 - val_loss: 0.6946 - val_accuracy: 0.4536\n",
            "Epoch 162/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6942 - accuracy: 0.4987 - val_loss: 0.6945 - val_accuracy: 0.4536\n",
            "Epoch 163/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6929 - accuracy: 0.5065 - val_loss: 0.6944 - val_accuracy: 0.4536\n",
            "Epoch 164/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6935 - accuracy: 0.4884 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 165/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6930 - accuracy: 0.5090 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 166/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6937 - accuracy: 0.4910 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 167/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6954 - accuracy: 0.5090 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 168/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.6918 - accuracy: 0.5116 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 169/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.6925 - accuracy: 0.5090 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 170/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.7026 - accuracy: 0.4987 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 171/300\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.7018 - accuracy: 0.5039 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 172/300\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.6961 - accuracy: 0.5065 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 173/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6919 - accuracy: 0.5039 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 174/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.7001 - accuracy: 0.5039 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 175/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6913 - accuracy: 0.5013 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 176/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6970 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 177/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 178/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6939 - accuracy: 0.5013 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 179/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6939 - accuracy: 0.4987 - val_loss: 0.6943 - val_accuracy: 0.4536\n",
            "Epoch 180/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6937 - accuracy: 0.5013 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 181/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6920 - accuracy: 0.5065 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 182/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6929 - accuracy: 0.5013 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 183/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.6917 - accuracy: 0.5065 - val_loss: 0.6946 - val_accuracy: 0.4536\n",
            "Epoch 184/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.7018 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 185/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6930 - accuracy: 0.5065 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 186/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6926 - accuracy: 0.5090 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 187/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6937 - accuracy: 0.5013 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 188/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6940 - accuracy: 0.5013 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 189/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6933 - accuracy: 0.5013 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 190/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.6931 - accuracy: 0.5090 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 191/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6927 - accuracy: 0.5142 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 192/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6933 - accuracy: 0.4961 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 193/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6935 - accuracy: 0.4884 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 194/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6914 - accuracy: 0.5142 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 195/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6934 - accuracy: 0.5039 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 196/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6921 - accuracy: 0.5039 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 197/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6933 - accuracy: 0.4961 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 198/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6936 - accuracy: 0.5039 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 199/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6935 - accuracy: 0.4987 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 200/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6921 - accuracy: 0.5142 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 201/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6912 - accuracy: 0.5013 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 202/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6958 - accuracy: 0.5090 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 203/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6936 - accuracy: 0.5090 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 204/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6933 - accuracy: 0.4935 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 205/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6916 - accuracy: 0.5039 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 206/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 207/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6915 - accuracy: 0.5039 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 208/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.7028 - accuracy: 0.5116 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 209/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6930 - accuracy: 0.5039 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 210/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6933 - accuracy: 0.4987 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 211/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6947 - accuracy: 0.4935 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 212/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.6952 - accuracy: 0.5013 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 213/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.7087 - accuracy: 0.5039 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 214/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6929 - accuracy: 0.5090 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 215/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6953 - accuracy: 0.5039 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 216/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6931 - accuracy: 0.5065 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 217/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6933 - accuracy: 0.5013 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 218/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 219/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6922 - accuracy: 0.5065 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 220/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6935 - accuracy: 0.4987 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 221/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 222/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 223/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 224/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 225/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6934 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 226/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6981 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 227/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 228/300\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.6943 - accuracy: 0.5013 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 229/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 230/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 231/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 232/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 233/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 234/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 235/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 236/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6933 - accuracy: 0.5039 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 237/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.7014 - accuracy: 0.5065 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 238/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6927 - accuracy: 0.5065 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 239/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 240/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6935 - accuracy: 0.5013 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 241/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6953 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 242/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6951 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 243/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6917 - accuracy: 0.5065 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 244/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6918 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 245/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6927 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 246/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6937 - accuracy: 0.5039 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 247/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6935 - accuracy: 0.5039 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 248/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6914 - accuracy: 0.5039 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 249/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6992 - accuracy: 0.5065 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 250/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6939 - accuracy: 0.5013 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 251/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6933 - accuracy: 0.5065 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 252/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6916 - accuracy: 0.5116 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 253/300\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.6929 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 254/300\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.6943 - accuracy: 0.5013 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 255/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6906 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 256/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6913 - accuracy: 0.5065 - val_loss: 0.6933 - val_accuracy: 0.4536\n",
            "Epoch 257/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.7115 - accuracy: 0.5013 - val_loss: 0.6934 - val_accuracy: 0.4536\n",
            "Epoch 258/300\n",
            "13/13 [==============================] - 2s 147ms/step - loss: 0.6978 - accuracy: 0.4935 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 259/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.7261 - accuracy: 0.4987 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 260/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6942 - accuracy: 0.4987 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 261/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.7135 - accuracy: 0.4987 - val_loss: 0.6935 - val_accuracy: 0.4536\n",
            "Epoch 262/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6975 - accuracy: 0.5065 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 263/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.7012 - accuracy: 0.5116 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 264/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6967 - accuracy: 0.4935 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 265/300\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.6930 - accuracy: 0.5039 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 266/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6940 - accuracy: 0.5039 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 267/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6916 - accuracy: 0.5039 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 268/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6903 - accuracy: 0.5065 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 269/300\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.7137 - accuracy: 0.5013 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 270/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6915 - accuracy: 0.5065 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 271/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 272/300\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 273/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6936 - val_accuracy: 0.4536\n",
            "Epoch 274/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.7008 - accuracy: 0.5039 - val_loss: 0.6937 - val_accuracy: 0.4536\n",
            "Epoch 275/300\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 276/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6934 - accuracy: 0.5013 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 277/300\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.6922 - accuracy: 0.5039 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 278/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6928 - accuracy: 0.5039 - val_loss: 0.6938 - val_accuracy: 0.4536\n",
            "Epoch 279/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6978 - accuracy: 0.5013 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 280/300\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.6937 - accuracy: 0.5090 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 281/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6973 - accuracy: 0.5013 - val_loss: 0.6939 - val_accuracy: 0.4536\n",
            "Epoch 282/300\n",
            "13/13 [==============================] - 2s 142ms/step - loss: 0.6917 - accuracy: 0.5065 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 283/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6924 - accuracy: 0.5065 - val_loss: 0.6940 - val_accuracy: 0.4536\n",
            "Epoch 284/300\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.6935 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 285/300\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.7054 - accuracy: 0.5013 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 286/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6944 - val_accuracy: 0.4536\n",
            "Epoch 287/300\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.6920 - accuracy: 0.5039 - val_loss: 0.6943 - val_accuracy: 0.4536\n",
            "Epoch 288/300\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.6944 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 289/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6918 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 290/300\n",
            "13/13 [==============================] - 2s 142ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 291/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 292/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 293/300\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6943 - val_accuracy: 0.4536\n",
            "Epoch 294/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6944 - val_accuracy: 0.4536\n",
            "Epoch 295/300\n",
            "13/13 [==============================] - 2s 142ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6945 - val_accuracy: 0.4536\n",
            "Epoch 296/300\n",
            "13/13 [==============================] - 2s 145ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6945 - val_accuracy: 0.4536\n",
            "Epoch 297/300\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.6914 - accuracy: 0.5039 - val_loss: 0.6944 - val_accuracy: 0.4536\n",
            "Epoch 298/300\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6942 - val_accuracy: 0.4536\n",
            "Epoch 299/300\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "Epoch 300/300\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
            "4/4 [==============================] - 1s 65ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_pred, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "QokD1P28RvRq",
        "outputId": "88a72f83-16ce-467c-a46b-24ff3acee59d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-914f5ce79b2b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRvN-BUES2lt",
        "outputId": "3342d7b0-8126-42b5-c5a5-286718e13377"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778],\n",
              "       [0.49526778]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "jORaqiEEnSrb",
        "outputId": "26c5e260-555d-4f53-8738-58063fdb641b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "usOFpqxtnWkH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}